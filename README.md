# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ
Отчет по лабораторной работе #5 выполнил:
- Тарасенко Алексей Романович
- РИ-230913

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | * |
| Задание 2 | * | * |
| Задание 3 | * | * |

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

## Цель работы
Познакомиться с одной из первых моделей нейросетей - перцептроном и реализовать эту модель в Unity

## 1 Поиск агентом объекта на сцене.
После установки, запуска MLAgent и проекта на Unity я начал обучение:

1 модель:
![image](https://github.com/user-attachments/assets/79ec8610-9270-4d66-b310-e31be781f78a)

3 модели:
![image](https://github.com/user-attachments/assets/56f85254-d7d0-417b-af2b-3e0aa62e88ef)

9 моделей:
![image](https://github.com/user-attachments/assets/cebb7ec0-22e3-40bb-9f2d-0962c5a6f1c7)

27 моделей:
![image](https://github.com/user-attachments/assets/ab48f83e-90cf-47be-b7dd-dd7da42c0dbc)

## 2 Симулятор добычи ресурсов.
При запуске сцены все работает корректно.

![image](https://github.com/user-attachments/assets/395f1f3f-5665-4537-a0f0-9964281a76cb)

Графики оценки результатов обучения:

![image](https://github.com/user-attachments/assets/f3fc0150-0f7f-45dc-ab05-7b1dda6e38e4)


## Задание 1. Найдите внутри C# скрипта “коэффициент корреляции” и сделать выводы о том, как он влияет на обучение модели
Ход работы:
Под коэффициентом корреляции можно понимать это строку SetReward(1.0f); - выдать 1 награду Она влияет на награду за правильное обучение и её можно считать нужным нам коэффициентом. Либо коэффициентом корреляции можно будет назвать такие данные как:
Позиция цели Target.localPosition

Позиция агента this.transform.localPosition

Скорость rBody.velocity.x и rBody.velocity.z

Поскольку от них завивит выдача этой самой награды.

## Задание 2. Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели. Привести описание не менее трех параметров.
Ход работы:
- max_steps:
Этот параметр устанавливает максимальное количество шагов, которые модель может сделать в процессе обучения. Чем больше это число, тем лучше модель будет обучена.
- trainer_type:
Этот параметр определяет тип алгоритма, который используется для интеллектуального обучения модели.
- num_layers:
Этот параметр определяет количество слоёв в обучающей сети. Чем больше слоёв, тем глубже модель.
  
## Задание 3. Приведите примеры, для каких игровых задачи и ситуаций могут использоваться примеры 1 и 2 с ML-Agent’ом. В каких случаях проще использовать ML-агент, а не писать программную реализацию решения?
Ход работы:

- Если модель научится отслеживать цель, то её можно использовать, например, для преследования игрока. Также можно направлять любой снаряд с самонаведением в цель честно, а не при помощи уловок.
- Вторую модель можно представить в виде курьера, перемещающегося между двумя точками.
ML-агент может быть полезен, когда задача имеет множество вариантов решения или не имеет определённого алгоритма решения, то есть множество возможных результатов. Также агент может быть полезен, если алгоритм решения невероятно сложен и его реализация вручную требует больших ресурсов и времени. например если нужно балансировать большое количество переменных.

## Выводы
Я изучил систему ML-агента в юнити, научился обучать готовые модели и тестировать их
| Plugin | README |
| ------ | ------ |
| Dropbox | [plugins/dropbox/README.md][PlDb] |
| GitHub | [plugins/github/README.md][PlGh] |
| Google Drive | [plugins/googledrive/README.md][PlGd] |
| OneDrive | [plugins/onedrive/README.md][PlOd] |
| Medium | [plugins/medium/README.md][PlMe] |
| Google Analytics | [plugins/googleanalytics/README.md][PlGa] |

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
